\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}
\usepackage{amsmath, amssymb}
\usepackage{graphicx}
\usepackage{natbib}
\usepackage{geometry}
\geometry{margin=1in}
\title{Regresi\'on Log\'istica en la Investigaci\'on M\'edica}
\author{Carlos}
\date{Abril 2025}

\begin{document}

\maketitle


\section{Resumen}

Las técnicas de regresión son versátiles en su aplicación a la investigación médica, ya que pueden medir asociaciones, predecir resultados y controlar los efectos de confusión. La regresión logística es una técnica eficiente y poderosa para analizar el efecto de un grupo de variables independientes sobre un resultado binario al cuantificar la contribución única de cada variable independiente.

Utilizando componentes de la regresión lineal reflejados en la escala logit, la regresión logística identifica iterativamente la combinación lineal más fuerte de variables con la mayor probabilidad de detectar el resultado observado. Consideraciones importantes incluyen seleccionar variables independientes relevantes, cumplir con los supuestos y elegir una estrategia adecuada de construcción del modelo.

Los supuestos básicos que deben cumplirse para la regresión logística incluyen independencia de errores, linealidad en el logit para variables continuas, ausencia de multicolinealidad y falta de valores atípicos influyentes. Se recomienda tener un número adecuado de eventos por variable para evitar el sobreajuste.

Las estrategias de construcción de modelos incluyen enfoques directo, secuencial/jerárquico y escalonado, cada uno con énfasis diferente. Antes de llegar a conclusiones definitivas, se debe cuantificar formalmente la validez interna y externa del modelo. El ajuste del modelo se evalúa mediante medidas como el logaritmo de verosimilitud y pruebas de bondad de ajuste. Los resultados se presentan habitualmente como razones de momios (OR) con intervalos de confianza del 95\%.

\section{Tipos de Regresión}

Existen distintos tipos de regresión dependiendo de los objetivos de investigación y el formato de las variables. La regresión lineal se usa comúnmente para resultados continuos y asume una relación lineal entre la variable dependiente y las independientes:

\[
\hat{Y} = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \ldots + \beta_i X_i
\]

donde:
\begin{itemize}
  \item $\beta_0$ es la ordenada al origen.
  \item $\beta_1 X_1 + \beta_2 X_2 + \ldots + \beta_i X_i$ representa el valor ponderado de las variables independientes.
\end{itemize}

La regresión logística, sin embargo, es preferida cuando el resultado es binario. La fórmula es:

\[
P(\hat{Y}_i) = \frac{e^{\beta_0 + \beta_1 X_1 + \beta_2 X_2 + \ldots + \beta_i X_i}}{1 + e^{\beta_0 + \beta_1 X_1 + \beta_2 X_2 + \ldots + \beta_i X_i}}
\]

Esta transforma la salida de la regresión lineal a una probabilidad entre 0 y 1 mediante la escala logit:

\[
\ln\left( \frac{\hat{Y}}{1 - \hat{Y}} \right) = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \ldots + \beta_i X_i
\]

\section{Supuestos de la Regresión Logística}

\begin{itemize}
  \item \textbf{Independencia de errores:} Las observaciones deben ser independientes entre sí.
  \item \textbf{Linealidad en el logit:} Las variables continuas deben tener una relación lineal con el logit del resultado.
  \item \textbf{Ausencia de multicolinealidad:} No debe haber redundancia entre variables independientes.
  \item \textbf{Ausencia de valores atípicos influyentes:} Estos pueden distorsionar los coeficientes y reducir la validez del modelo.
\end{itemize}

\section{Número de Variables a Incluir}

Se recomienda seguir la regla práctica de tener entre 10 y 20 eventos por variable independiente. Incluir demasiadas variables con un tamaño de muestra pequeño puede causar sobreajuste y generar errores estándar elevados.

\section{Estrategias de Construcción del Modelo}

\begin{itemize}
  \item \textbf{Directa:} Todas las variables se introducen simultáneamente.
  \item \textbf{Secuencial/Jerárquica:} Se introducen variables por orden de prioridad.
  \item \textbf{Escalonada (Stepwise):} Basada en criterios estadísticos, como selección hacia adelante o eliminación hacia atrás.
\end{itemize}

\section{Validación del Modelo}

\subsection{Validación Interna}

\begin{itemize}
  \item Método \textit{holdout}: dividir el conjunto en entrenamiento y prueba.
  \item \textit{k-fold cross-validation}: subdividir la muestra en k subconjuntos.
  \item \textit{Bootstraping}: remuestreo con reemplazo.
\end{itemize}

\subsection{Validación Externa}

Evaluar el modelo en una muestra diferente al conjunto original, para estimar su aplicabilidad clínica y robustez.

\section{Interpretación del Modelo}

\subsection{Ajuste General del Modelo}

Se evalúa mediante estadísticos como Chi-cuadrado, desviación residual, y prueba de bondad de ajuste de Hosmer-Lemeshow. Un buen ajuste implica poca diferencia entre observados y predichos.

\subsection{Discriminación del Modelo}

Se evalúa con:
\begin{itemize}
  \item Tablas de clasificación.
  \item Área bajo la curva ROC (AUROC), donde 0.5 indica azar y 1.0 discriminación perfecta.
\end{itemize}

\subsection{Resultados de las Variables Independientes}

Los coeficientes se interpretan mediante razones de momios (odds ratios, OR):

\[
OR = e^{\beta_i}
\]

\begin{itemize}
  \item Un OR de 1.5 implica que una variable aumenta en un 50\% las probabilidades del evento.
  \item Los OR ajustados consideran el efecto de las demás variables.
  \item Se reportan con intervalos de confianza del 95\%.
\end{itemize}

\section{Conclusión}

La regresión logística es una herramienta estadística robusta para analizar resultados binarios en investigación médica. Su correcto uso requiere comprensión teórica, cumplimiento de supuestos y validación adecuada.


\section*{Resumen}
Las t\'ecnicas de regresi\'on son vers\'atiles en su aplicaci\'on a la investigaci\'on m\'edica porque pueden medir asociaciones, predecir resultados y controlar efectos de variables de confusi\'on. Como una de estas t\'ecnicas, la regresi\'on log\'istica es una forma eficiente y poderosa de analizar el efecto de un grupo de variables independientes sobre un resultado binario, cuantificando la contribuci\'on \'unica de cada variable independiente. Utilizando componentes de la regresi\'on lineal reflejados en la escala logit, la regresi\'on log\'istica identifica iterativamente la combinaci\'on m\'as fuerte de variables con la mayor probabilidad de detectar el resultado observado. Consideraciones importantes al realizar una regresi\'on log\'istica incluyen la selecci\'on de variables independientes, asegurando que se cumplan los supuestos relevantes y eligiendo una estrategia de construcci\'on de modelo apropiada. Para la selecci\'on de variables independientes, uno debe guiarse por factores como teor\'ia aceptada, investigaciones emp\'iricas previas, consideraciones cl\'inicas y an\'alisis estad\'isticos univariantes, con reconocimiento de variables de confusi\'on potenciales que deben tenerse en cuenta. Los supuestos b\'asicos que deben cumplirse para la regresi\'on log\'istica incluyen independencia de errores, linealidad en el logit para variables continuas, ausencia de multicolinealidad y falta de valores at\'ipicos altamente influyentes. Adem\'as, debe haber un n\'umero adecuado de eventos por variable independiente para evitar un modelo sobreajustado, con "reglas generales" recomendadas que van de 10 a 20 eventos por covariable. En cuanto a estrategias de construcci\'on de modelos, hay tres tipos generales: directa/est\'andar, secuencial/jer\'arquica y paso a paso/estad\'istica, cada una con un \'enfasis y prop\'osito diferente. Antes de llegar a conclusiones definitivas a partir de los resultados de cualquiera de estos m\'etodos, se debe cuantificar formalmente la validez interna del modelo (es decir, replicabilidad dentro del mismo conjunto de datos) y la validez externa (es decir, generalizabilidad m\'as all\'a de la muestra actual). El ajuste general del modelo de regresi\'on log\'istica a los datos de la muestra se eval\'ua utilizando diversas medidas de bondad de ajuste, donde un mejor ajuste se caracteriza por una menor diferencia entre los valores observados y predichos por el modelo. Tambi\'en se recomienda el uso de estad\'isticas de diagn\'ostico para evaluar a\'un m\'as la adecuaci\'on del modelo. Finalmente, los resultados para las variables independientes suelen informarse como razones de momios (odds ratios, OR) con intervalos de confianza del 95\% (IC).

\section*{Referencias}
\begin{enumerate}
  \item Darlington RB. Regression and Linear Models. Columbus, OH: McGraw-Hill Publishing Company, 1990.
  \item Tabachnick BG, Fidell LS. Using Multivariate Statistics. 5th ed. Boston, MA: Pearson Education, Inc., 2007.
  \item Hosmer DW, Lemeshow SL. Applied Logistic Regression. 2nd ed. Hoboken, NJ: Wiley-Interscience, 2000.
  \item Campbell DT, Stanley JC. Experimental and Quasi-experimental Designs for Research. Boston, MA: Houghton Mifflin Co., 1963.
  \item Stokes ME, Davis CS, Koch GG. Categorical data analysis using the SAS system (2nd ed). Cary, NC: SAS Institute, Inc., 2000.
  \item Newgard CD, Hedges JR, Arthur M, Mullins RJ. Advanced statistics: the propensity score\textendash a method for estimating treatment effect in observational research. Acad Emerg Med. 2004; 11:953\textendash 61.
  \item Newgard CD, Haukoos JS. Advanced statistics: missing data in clinical research\textendash part 2: multiple imputation. Acad Emerg Med. 2007; 14:669\textendash 78.
  \item Allison PD. Logistic Regression Using the SAS System: Theory and Application. Cary, NC: SAS Institute, Inc., 1999.
  \item Peduzzi P, Concato J, Kemper E, Holford TR, Feinstein AR. A simulation study of the number of events per variable in logistic regression analysis. J Clin Epidemiol. 1996; 49:1373\textendash 9.
  \item Agresti A. An Introduction to Categorical Data Analysis. Hoboken, NJ: Wiley, 2007.
  \item Feinstein AR. Multivariable Analysis: An Introduction. New Haven, CT: Yale University Press, 1996.
  \item Altman DG, Royston P. What Do We Mean by Validating a Prognostic Model? Stats Med. 2000; 19:453\textendash 73.
  \item Kohavi R. A study of cross-validation and bootstrap for accuracy estimation and model selection. In: Proceedings of the 14th International Joint Conference on Artificial Intelligence (IJCAI). Montreal, Quebec, Canada, August 20\textendash 25, 1995. 1995:1137\textendash 43.
  \item Efron B, Tibshirani R. An Introduction to the Bootstrap. New York: Chapman \& Hall, 1993.
  \item Miller ME, Hiu SL, Tierney WM. Validation techniques for logistic regression models. Stat Med. 1991; 10:1213\textendash 26.
  \item Hosmer DW, Hosmer T, Le Cessie S, Lemeshow S. A comparison of goodness-of-fit tests for the logistic regression model. Stat Med. 1997; 16:965\textendash 80.
  \item Kuss O. Global goodness-of-fit tests in logistic regression with sparse data. Stat Med. 2002; 21:3789\textendash 801.
  \item Zou KH, O\'Malley AJ, Mauri L. Receiver-operating characteristic analysis for evaluating diagnostic tests and predictive models. Circulation 2007; 115:654\textendash 7.
\end{enumerate}

\end{document}
